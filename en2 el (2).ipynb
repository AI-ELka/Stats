{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration numérique 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Définir les paramètres du modèle\n",
    "n = 30\n",
    "p = 30\n",
    "alpha = 0.01\n",
    "\n",
    "# Données d'échantillon\n",
    "X = np.array([13, 130, 39, 33, 10,13, 68, 18, 3, 11,38, 23, 60, 5, 9,59, 5, 86, 22, 70,58, 3, 167, 15, 30, \n",
    "     8, 20, 67, 26, 19])\n",
    "Y = np.array([14, 8, 20, 3, 138,122, 78, 69, 111, 3,128, 31, 18, 35, 111,109, 36, 27, 32, 35,12, 27, 8, 3,\n",
    "     80,91, 68, 66, 176, 15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimateur du maximum de vraisemblance du paramètre $ \\theta = (\\mu_0, \\mu_1, \\sigma_0, \\sigma_1) $\n",
    "\n",
    "$$\n",
    "f_{n, p, \\mu_0, \\mu_1, \\sigma_0, \\sigma_1}(x_1, x_2, \\ldots, x_n, y_1, \\ldots, y_p) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}  e^{-\\frac{(x_i - \\mu_0)^2}{2\\sigma_0^2}} \\prod_{i=1}^{p} \\frac{1}{\\sqrt{2\\pi\\sigma_1^2}}  e^{-\\frac{(y_i - \\mu_1)^2}{2\\sigma_1^2}}\n",
    "$$\n",
    "\n",
    "Donc:\n",
    "\n",
    "$$\n",
    "\\ln(f_{n, p, \\mu_0, \\mu_1, \\sigma_0, \\sigma_1}(x_1, x_2, \\ldots, x_n, y_1, \\ldots, y_p)) = -\\ln((2\\pi)^{\\frac{n}{2}}\\sigma_0^n) - \\ln((2\\pi)^{\\frac{p}{2}}\\sigma_1^p) - \\frac{1}{2\\sigma_0^2}\\sum_{i=1}^{n} (x_i-\\mu_0)^2 - \\frac{1}{2\\sigma_1^2}\\sum_{i=1}^{p} (y_i-\\mu_1)^2\n",
    "$$\n",
    "\n",
    "On constate que cette fonction est une somme de deux fonctions à variables indépandentes, chercher le maximum de cette fonction revient à chercher le maximum des deux fonctions et comme on connait l'estimateur de maximum de vraisemblence d'une variable gaussienne on trouve:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_0 = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "$$\n",
    "\\hat{\\mu}_1 = \\frac{1}{p}\\sum_{i=1}^{p} y_i\n",
    "$$\n",
    "$$\n",
    "\\hat{\\sigma}_0^2 = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\hat{\\mu}_0)^2\n",
    "$$\n",
    "$$\n",
    "\\hat{\\sigma}_1^2 = \\frac{1}{p}\\sum_{i=1}^{p} (y_i - \\hat{\\mu}_1)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_0 =  37.6\n",
      "mu_1 =  55.8\n",
      "sigma_0 =  1431.84\n",
      "sigma_1 =  2251.36\n"
     ]
    }
   ],
   "source": [
    "# les moyennes et variances\n",
    "m0 = np.mean(X)\n",
    "m1 = np.mean(Y)\n",
    "sigma0_2 = 1/n*np.linalg.norm(X-m0)**2\n",
    "sigma1_2 = 1/n*np.linalg.norm(Y-m1)**2\n",
    "sigma_2 = (n*sigma0_2+p*sigma1_2)/(n+p)\n",
    "\n",
    "\n",
    "# les résultas\n",
    "print('mu_0 = ', m0)\n",
    "print('mu_1 = ', m1)\n",
    "print('sigma_0 = ', sigma0_2)\n",
    "print('sigma_1 = ', sigma1_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $\\Theta = \\{(\\mu_0, \\mu_1, \\sigma_{0}^2, \\sigma_{1}^2) \\in \\mathbb{R}^2 \\times (\\mathbb{R}^{*+})^2 \\}$ et $\\Theta_{0} = \\{(\\mu_0, \\mu_1, \\sigma_{0}^2, \\sigma_{1}^2) \\in \\mathbb{R}^2\\times(\\mathbb{R}^{*+})^2$ tq $\\sigma_{0}^2 = \\sigma_{1}^2 \\} \\newline $\n",
    "Soit $L(\\theta, Z)$ la vraisemblance de l'observation $Z$ sous la loi $P_{\\theta}$. Le rapport de vraisemblance généralisé est défini par\n",
    "$$\n",
    "\\Lambda(Z) = \\frac{\\sup_{\\theta \\in \\Theta_0} L(\\theta, Z)}{\\sup_{\\theta \\in \\Theta} L(\\theta, Z)}\n",
    "$$\n",
    "Or $$ \\sup_{\\theta \\in \\Theta_0} L(\\theta, Z) = L({\\theta _{nulle}},Z)  $$ \n",
    "où $\\theta _{nulle} = (n,p,\\hat{\\mu_0} , \\hat{\\mu_1} , \\hat{\\sigma}^2 ,\\hat{\\sigma}^2)$  avec $\\hat{\\sigma}$ obtenu en maximisant $L(\\theta, Z)$ sur \n",
    "$ \\{ \\Theta_{0} :\\sigma_0 = \\sigma_1 \\} $ :\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or $$ \\sup_{\\theta \\in \\Theta_0} L(\\theta, Z) = L({\\theta _{nulle}},Z)  $$ \n",
    "où $\\theta _{nulle} = (n,p,\\hat{\\mu_0} , \\hat{\\mu_1} , \\hat{\\sigma}^2 ,\\hat{\\sigma}^2)$  avec $\\hat{\\sigma}$ obtenu en maximisant $L(\\theta, Z)$ sur \n",
    "$ \\{ \\Theta_{0} :\\sigma_0 = \\sigma_1 \\} $ :  \n",
    "Dans ce cas, la fonction de log-vraisemblance \n",
    "$$\n",
    "\\ln(f_{n, p, \\mu_0, \\mu_1, \\sigma^2, \\sigma^2}(x_1, x_2, \\ldots, x_n, y_1, \\ldots, y_p)) = - \\ln((2\\pi)^{\\frac{n+p}{2}}(\\sigma^2)^{n+p}) - \\frac{1}{2\\sigma^2} \\{ \\sum_{i=1}^{n} (x_i-\\mu_0)^2 + \\sum_{i=1}^{p} (y_i-\\mu_1)^2\\}\n",
    "$$\n",
    "on maximise tout d'abord les termes en $\\mu_0$ et $\\mu_1$ qui donne le même resulat que la question précédente : \n",
    "$$\n",
    "\\hat{\\mu}_0 = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "$$\n",
    "\\hat{\\mu}_1 = \\frac{1}{p}\\sum_{i=1}^{p} y_i\n",
    "$$\n",
    "on dérive après par rapport à $\\sigma^2 \\newline$\n",
    "on trouve donc $$ \\frac{(n+p)}{\\sigma^2}-\\frac{||X-\\hat{\\mu_0} I_n||^2+||Y-\\hat{\\mu_1} I_p||^2}{\\sigma^4}$$\n",
    "cette fonction s'annule en \n",
    "$$  \\hat{\\sigma}^2 = \\frac{1}{n+p} [ ||X-\\hat{\\mu_0} I_n||^2+||Y-\\hat{\\mu_1} I_p||^2 ] $$ \n",
    "D'où \n",
    "\\begin{align}\n",
    "    \\Lambda(Z) &= \\frac{L({\\theta _{nulle}},Z) }{L((n,p,\\hat{\\mu_0} , \\hat{\\mu_1} , \\hat{\\sigma_0}^2 , \\hat{\\sigma_1}^2),Z) } \\\\\n",
    "    &=\\frac{\\frac{1}{\\hat{\\sigma}^{2(n+p)}}}{\\frac{1}{\\hat{\\sigma_0}^{2 n}}  \\frac{1}{\\hat{\\sigma_1}^{2p}}} \\\\\n",
    "    &=\\frac{\\hat{\\sigma_0}^{2 n} \\hat{\\sigma_1}^{2p}}{\\hat{\\sigma}^{2(n+p)}} \\\\\n",
    "    &=(\\frac{\\hat{\\sigma_0}^{2}}{\\hat{\\sigma}^{2}})^n  (\\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma}^{2}})^p \\\\\n",
    "    &=(n+p)^{(n+p)} (\\frac{1}{n+p \\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}}})^n (\\frac{1}{p+ n \\frac{\\hat{\\sigma_0}^{2}}{\\hat{\\sigma_1}^{2}}} )^p \n",
    "\\end{align}\n",
    "Or $ x \\mapsto (\\frac{1}{n+p x})^n (\\frac{1}{p+ \\frac{n}{x} } )^p =  x^p (\\frac{1}{n+p x})^{n+p} $  est strictement croissante sur $[0;1]$ , la dérivée de son logarithme étant égale à $ \\frac{np(1-x)}{x(n+px)}$   \n",
    "Et dans notre jeu d'hypothèses : $ \\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}} \\le 1$ , donc la région de rejet est de la forme $ \\{\\Lambda(Z) \\leq d_\\alpha\\}$ pour un niveau $\\alpha$ donné , ce qui équivaut \n",
    "$$ R_\\alpha = \\{ \\frac{p(n-1)}{n(p-1)}\\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}} \\leq c_\\alpha \\}$$\n",
    "La fonction de puissance est $\\theta \\mapsto \\mathbb{P}_\\theta(\\{ \\frac{p(n-1)}{n(p-1)}\\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}} \\leq c_\\alpha \\}) \\newline $\n",
    "$ \\mathbb{P}_\\theta(\\{ \\frac{p(n-1)}{n(p-1)}\\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}} \\leq c_\\alpha \\}) = \\mathbb{P}_\\theta(\\{ \\frac{p(n-1)\\frac{\\hat{\\sigma_1}^{2}}{\\sigma_1^2}}{n(p-1)\\frac{\\hat{\\sigma_0}^{2}}{\\sigma_0^2}} \\leq c_\\alpha.\\frac{\\sigma_0^2}{\\sigma_1^2} \\}) \\newline $\n",
    "On a $ n\\frac{\\hat{\\sigma_0}^{2}}{\\sigma_0^2} \\sim \\chi^2(n-1) $ et $p\\frac{\\hat{\\sigma_1}^{2}}{\\sigma_1^2} \\sim \\chi^2(p-1)$\n",
    "Donc sous $\\theta$ $\\frac{p(n-1)\\frac{\\hat{\\sigma_1}^{2}}{\\sigma_1^2}}{n(p-1)\\frac{\\hat{\\sigma_0}^{2}}{\\sigma_0^2}} \\sim F(p-1,n-1)$ loi de Fisher de paramètre p-1, n-1 $\\newline$\n",
    "Soit $H$ la fonction de répartition de cette loi. On a alors la fonction de puissance est $ \\theta \\mapsto H(c_\\alpha.\\frac{\\sigma_0^2}{\\sigma_1^2}) \\newline$\n",
    "et donc la taille est $ \\sup_{\\theta \\in \\Theta_0} H(c_\\alpha.\\frac{\\sigma_0^2}{\\sigma_1^2}) = H(c_\\alpha)$\n",
    "et donc, pour $c_\\alpha$, on prend le quantile d'ordre $\\alpha$ de $F(p-1,n-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La p-valeur $\\bar{\\alpha}(Z) =inf \\{\\alpha \\in [0,1] , \\frac{p(n-1)}{n(p-1)}\\frac{\\hat{\\sigma_1}^{2}(Z)}{\\hat{\\sigma_0}^{2}(Z)} \\leq f_\\alpha\\}  $   \n",
    "Comme $\\alpha \\mapsto f_\\alpha$ est croissante  , la p-valeur vérifie $c_{\\bar{\\alpha}} = \\frac{p(n-1)}{n(p-1)}\\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}}$  \n",
    "Ainsi , \n",
    "$$ \\bar{\\alpha} = F(\\frac{p(n-1)}{n(p-1)}\\frac{\\hat{\\sigma_1}^{2}}{\\hat{\\sigma_0}^{2}})$$\n",
    "Où F la fonction de répartition d'une loi de $Fisher(p-1,n-1)$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalle de confiance de $ \\mu_0 - \\mu_1 $  de niveau de confiance 1 − α\n",
    "\n",
    "Posons\n",
    "$$ \\hat{\\mu_{0}} = \\frac{1}{n} \\sum_{i=1}^{n} X_i  \\quad , \\quad   \\hat{\\mu_{1}} = \\frac{1}{p} \\sum_{i=1}^{n} Y_i $$\n",
    "On a   \n",
    "$\\hat{\\mu_{0}} - \\hat{\\mu_{1}} \\sim \\mathcal{N}(\\mu_0 - \\mu_1, \\sigma^2 \\cdot \\left(\\frac{1}{p} + \\frac{1}{n}\\right))$ , les $(X_i)_{i=1,...,n} $ étant independants  et independants des $(Y_i)_{i=1,...,p} $\n",
    "\n",
    "Donc $$ \\frac{\\hat{\\mu_{0}} - \\hat{\\mu_{1}} - (\\mu_0 - \\mu_1)}{\\sigma \\sqrt{\\frac{1}{p} + \\frac{1}{n}}} \\sim \\mathcal{N}(0,1) $$  \n",
    "Or l'estimateur de $\\sigma^2 $ est:  $$  \\hat{\\sigma}^2 = \\frac{1}{n+p} [ ||X-\\hat{\\mu_0} I_n||^2+||Y-\\hat{\\mu_1} I_p||^2 ] $$ \n",
    "Alors\n",
    " $$ (n+p) \\frac{\\hat{\\sigma}^2}{\\sigma^2} \\sim \\mathcal{\\chi^2}(n+p-2)$$\n",
    "Donc\n",
    "$$ \\frac{\\frac{\\hat{\\mu_{0}} - \\hat{\\mu_{1}} - (\\mu_0 - \\mu_1)}{\\sigma \\sqrt{\\frac{1}{p} + \\frac{1}{n}}}}{ \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{\\sigma^2}/(n+p-2)}} = \\frac{\\frac{\\hat{\\mu_{0}} - \\hat{\\mu_{1}} - (\\mu_0 - \\mu_1)}{ \\sqrt{\\frac{1}{p} + \\frac{1}{n}}}}{ \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}} \\sim t(n+p-2)$$\n",
    "Donc cela suit une loi de Student à n+p-2 degrés de liberté.\n",
    "Soit $q_{1 - \\frac{\\alpha}{2}} $ le quantile d'ordre $ {1 - \\frac{\\alpha}{2}} $ d'une loi de Student. On a alors:\n",
    "$$ \\mathbb{P}(-q_{1 - \\frac{\\alpha}{2}} \\leq \\frac{\\frac{\\hat{\\mu_{0}} - \\hat{\\mu_{1}} - (\\mu_0 - \\mu_1)}{ \\sqrt{\\frac{1}{p} + \\frac{1}{n}}}}{ \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}} \\leq q_{1 - \\frac{\\alpha}{2}})$$\n",
    "$$ = \\mathbb{P}(-q_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}} + (\\hat{\\mu_{0}} - \\hat{\\mu_{1}}) \\leq \\mu_0 - \\mu_1 \\leq q_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}} + (\\hat{\\mu_{0}} - \\hat{\\mu_{1}})) $$\n",
    "$$ = 1-\\alpha$$\n",
    "Donc\n",
    "$ A(Z) = [-q_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}} + (\\hat{\\mu_{0}} - \\hat{\\mu_{1}}), q_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}} + (\\hat{\\mu_{0}} - \\hat{\\mu_{1}})] $ est un intervalle de confiance de µ0 − µ1 de niveau de confiance 1 − α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'intervalle de confiance : [-48.21453460411288, 11.814534604112886]\n"
     ]
    }
   ],
   "source": [
    "# l'intervalle de confiance\n",
    "c = stats.t.ppf(1 - alpha/2, n + p - 2)*((np.sqrt(sigma_2)*(n+p))/np.sqrt((n+p-2)*n*p))\n",
    "intervalle = [m0-m1 - c , m0-m1 + c ]\n",
    "print(\"L'intervalle de confiance :\", intervalle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de niveau α = 0.01 de l’hypothèse\n",
    "$$ H_{0} : \\mu_{0} = \\mu_{1}, H_{1} : \\mu_{0} \\neq \\mu_{1} $$\n",
    "On pose $ A(Z)$ l'intervalle de confiance de la question précédente.\n",
    "En utilisant le résultat de la question précédente, on prend l'intervalle de confiance de $\\mu_{0} - \\mu_{1}$ comme zone d'acceptation.\n",
    "Donc, on prend comme test la fonction définie par:\n",
    "$$ \\phi(Z) = \\mathbb{1}_{0 \\in B(Z)} $$ \n",
    "avec $ B(Z) = \\mathbb{R}\\setminus A(Z) $\n",
    "$$ \\mathbb{P}_{H_{0}}(\\phi(Z) = 1) = \\mathbb{P}_{H_{0}}(0 \\in B(Z)) = \\mathbb{P}_{H_{0}}(\\mu_{0} - \\mu_{1} \\in B(Z)) = 1 - \\mathbb{P}_{H_{0}}(\\mu_{0} - \\mu_{1} \\in A(Z)) = 1 - (1 - \\alpha) = \\alpha $$\n",
    "Donc il s'agit bien d'un test de niveau $ \\alpha $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La p-valeur du test\n",
    "$$ H_{0} : \\mu_{0} = \\mu_{1}, H_{1} : \\mu_{0} \\neq \\mu_{1} $$\n",
    "si $ \\alpha < \\alpha{'} $ Alors $ \\phi_{\\alpha}(Z) = 1 \\subseteq \\phi_{\\alpha{'}}(Z) = 1 $\n",
    "$$ \\hat{\\alpha}(Z) = inf\\{ \\alpha \\in [0, 1]: \\phi_{\\alpha}(Z) = 1 \\} $$\n",
    "\n",
    "$ \\alpha = \\hat{\\alpha}(Z) $ vérifie $ \\left|q_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}\\right| = \\left|\\hat{\\mu_0} - \\hat{\\mu_1}\\right| $\n",
    "Donc\n",
    "$$ q_{1 - \\frac{\\alpha}{2}} = \\frac{\\left|\\hat{\\mu_0} - \\hat{\\mu_1}\\right|}{\\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}} $$\n",
    "D'où\n",
    "$$ \\bar{\\alpha}(Z) = 2 - 2 G(\\frac{\\left|\\hat{\\mu_0} - \\hat{\\mu_1}\\right|}{\\sqrt{\\frac{1}{p} + \\frac{1}{n}} \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}}) $$\n",
    "\n",
    "Avec $G$ est la fonction de répartition d'une loi de Student à $n+p-2$ degré de liberté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La p-valeur du test : 0.11175016168340379\n"
     ]
    }
   ],
   "source": [
    "alphabar = 2 - 2*stats.t.cdf(np.sqrt(((n+p-2)*n*p)/(sigma_2*(n+p)**2)) * abs(m0-m1) , n + p - 2)\n",
    "print(\"La p-valeur du test :\",alphabar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de niveau α = 0.01 de l’hypothèse\n",
    "$$ H_{0} : \\mu_{0} \\leq \\mu_{1}, H_{1} : \\mu_{0} \\gt \\mu_{1} $$\n",
    "On prend alors le Test qui y a pour zone de rejet $ R = \\{ \\hat{\\mu_0} - \\hat{\\mu_1} \\ge c_{\\alpha} \\} $\n",
    "\n",
    "avec $c_{\\alpha}$ à determiner. \n",
    "\n",
    "la fonction de puissance de test est : $ \\theta \\mapsto \\mathbb{P}_{\\theta}( \\hat{\\mu_0} - \\hat{\\mu_1} \\ge c_{\\alpha} ) $\n",
    "\n",
    "On a $$ \\mathbb{P}_{\\theta}( \\hat{\\mu_0} - \\hat{\\mu_1} \\ge c_{\\alpha} ) = \\mathbb{P}_{\\theta}( \\frac{\\frac{\\hat{\\mu_0} - \\hat{\\mu_1} - (\\mu_0 - \\mu_1)}{ \\sqrt{\\frac{1}{p} + \\frac{1}{n}}}}{ \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}} \\geq \\frac{\\frac{c_{\\alpha} - (\\mu_0 - \\mu_1)}{ \\sqrt{\\frac{1}{p} + \\frac{1}{n}}}}{ \\sqrt{(n+p) \\frac{\\hat{\\sigma}^2}{n+p-2}}})$$\n",
    "$$ = \\mathbb{P}( t(n+p-2) \\geq \\frac{ (c_{\\alpha} - (\\mu_{0}-\\mu_{1})).\\sqrt{n+p-2}}{\\sqrt{\\hat{\\sigma}^2.np}} )$$\n",
    "$$ = 1 - G(\\frac{ (c_{\\alpha} - (\\mu_{0}-\\mu_{1})).\\sqrt{(n+p-2).n.p}}{\\hat{\\sigma}.(n+p)})$$\n",
    "Avec $G$ est la fonction de répartition d'une loi de Student à $n+p-2$ degré de liberté\n",
    "sous l'hypothése $H_{0}$ maximiser $ \\mathbb{P}_{\\theta}( \\hat{\\mu_0} - \\hat{\\mu_1} \\ge c_{\\alpha} )$ revient à minimiser $\\frac{ (c_{\\alpha} - (\\mu_{0}-\\mu_{1})).\\sqrt{(n+p-2).n.p}}{\\hat{\\sigma}.(n+p)}$ car $G$ est croissante et donc maximiser $\\mu_{0}-\\mu_{1}$\n",
    "et comme on a $ \\mu_{0}-\\mu_{1} \\leq 0 $ donc $0$ est la valeur maximale et donc la taille de ce test est : $$ 1 - G(\\frac{ c_{\\alpha}.\\sqrt{(n+p-2).n.p}}{\\hat{\\sigma}.(n+p)}) = \\alpha $$\n",
    "et alors $$ c_{\\alpha} = \\frac{\\hat{\\sigma}.(n+p)}{\\sqrt{(n+p-2).n.p}}.G^{-1}(1-\\alpha)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.96145688138722"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la valeur critique\n",
    "calpha = (np.sqrt(sigma_2)*(n+p))/np.sqrt((n+p-2)*n*p) * stats.t.ppf(1 - alpha, n + p - 2)\n",
    "print(\"Le seuil critique :\",calpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La p-valeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La p-valeur $\\bar{\\alpha}(Z) =inf \\{\\alpha \\in [0,1] ,  \\hat{\\mu_0} - \\hat{\\mu_1} \\ge c_{\\alpha} \\}  $   \n",
    "Comme $\\alpha \\mapsto c_\\alpha$ est décroissante  , la p-valeur vérifie $c_{\\bar{\\alpha}} =  \\hat{\\mu_0} - \\hat{\\mu_1}$  \n",
    "Ainsi , \n",
    "$$ \\bar{\\alpha} = 1 - G(\\frac{\\sqrt{(n+p-2).n.p}}{\\hat{\\sigma}.(n+p)}.(\\hat{\\mu_0} - \\hat{\\mu_1}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La p-valeur est : 0.9441249191582981\n"
     ]
    }
   ],
   "source": [
    "# la p-valeur\n",
    "alphabar = 1 - stats.t.cdf(np.sqrt(((n+p-2)*n*p)/(sigma_2*((n+p)**2))) * (m0-m1) , n + p - 2)\n",
    "print(\"La p-valeur est :\", alphabar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "On trouve que le hypothese nulle sigma0=sigma1 est accepetee\n",
    "Aussi , vu les p-valeurs de mu0=mu1 et mu0<=mu1 , on mu0<=mu1 est plus acceptable pour la valeur alpha donnee (meme si les deux hypotheses nulles sont acceptees ) donc en moyenne, les membres du groupe 0 ont un meilleur sens de l’orientation.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Les résultats de notre analyse indiquent que l'hypothèse nulle, $\\sigma_0 = \\sigma_1$, est acceptée. De plus, sous cette hypothèse, en considérant les p-valeurs pour $\\mu_0 = \\mu_1$ et $\\mu_0 \\leq \\mu_1$, l'hypothèse $\\mu_0 \\leq \\mu_1$ est préférable pour une valeur $\\alpha$ donnée, même si les deux hypothèses nulles sont acceptées. Ainsi, en moyenne, il semble que les membres du groupe 0 possèdent un meilleur sens de l'orientation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
